In this study, we are using information theoretic features to investigate deafness mutation loci, and the information theoretic features involved include: Entropy, Mutual Information, Conditional Mutual Information, and Cumulative Fourier Power Spectral Moments for a total of 107 dimensional features

In information theory, entropy is a measure of uncertainty or randomness. In the context of DNA sequences, entropy is a measure of the randomness inherent in the distribution of nucleotides. The concept of mutual information is employed to quantify the dependency between two variables, thereby capturing the correlation between different nucleotide positions in a DNA sequence. A high level of mutual information indicates the presence of strong relationships or co-evolution between the positions in question. The conditional mutual information, contingent on the presence of a third variable, quantifies the dependency between two variables within a defined context. In the context of DNA sequences, CMI can be employed to examine the impact of particular positions on others, thereby elucidating more intricate dependency structures. The measurement of uncertainty and signal spectrum spread is primarily achieved through the utilisation of cumulative Fourier power spectrum moments and central moments. The periodicity of DNA sequences can be detected and quantified through the utilisation of a discrete Fourier transform, whereby the power spectrum is subjected to analysis.

Web Resources
OMIM, https://www.omim.org/
ClinVar, https://www.ncbi.nlm.nih.gov/clinvar/
Deafness Variation Database v9.0, https://deafnessvariationdatabase.org/
NCBI, https://www.ncbi.nlm.nih.gov/
Gene4HL, http://www.genemed.tech/gene4hl/home
SNPnexus, https://www.snp-nexus.org/v4/

Inside the 'data' are the training set data and independent test set data.
The 'train' contains segments of the training dataset
'Prediction' contains the predicted data and results.
'Main' and 'valid' refer to some parts of the program.
